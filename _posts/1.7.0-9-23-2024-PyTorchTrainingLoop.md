# PyTorch Training Loop

```
# Pass the data through the model for a number of epochs (i.e. 100)
for epoch in range(epochs):
  # Put model in training mode (this is the default state of a model)
  model.train()
  # 1. Forward pass on train data using the forward() method inside
  y_pred = model(X_train)
  # 2. Calculate the loss (how different are the model's predictions ot the true values)
  loss = loss_fn(y_pred, y_true)
  # 3. Zero the gradients of the optimizer (they accumulate by default)
  optimizer.zero_grad()
  # 4. Perofrm backpropgation on the loss
  loss.backward()
  # 5. Progress/step the optimizer (gradient descent)
  optimizer.step()
```

### Breakdown of each step
Pass the data thorugh the model for a number of epochs (i.e. 100 for 100 passes of the data)

1. Pass the data through the model, this will perform the forward() method located within the model object

2. Calculate the loss value(How wrong the model's predictions are)

3. Zero the optimizer gradients(they accumulate every epoch, ero them to start fresh each forward pass)

4. Perform backpropgation on the loss function(compute the gradient of every parameter with requires_grad=True)

5. Step the optimizer to update the model's parameters with respect to the gradients calculated by loss.backward()
